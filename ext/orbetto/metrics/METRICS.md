# Trace Metrics with Plotly in Dash

As explained in the TRACE.md readme, perfetto is a very useful tool for displaying trace data,
but is limited in data size and display variability.
Therefore, as a proof of concept, some metrics are calculated in Python.
We use the perfbuf file generated by orbetto, the SQL trace processor from perfetto
and a program counter bitmap generated by CRoaring in orbetto.

## Visualising metrics:

To start the local dash server you need to pass a perfbuf file when analysing itm data or a bitmap for statement data.
Depending on which argument you pass, different metrics can be displayed. Use -h to see all options.
If you are using the -diff flag, you will need to provide a second perfbuf file to display the metrics based on the difference between the
between the two files. This is very useful for comparing different versions or settings between two runs.

```sh
# cd orbetto/metrics
# two metrics
python3 metrics.py -f /path/to/orbetto.perf -wq -dwq
# difference between two traces on one metric
python3 metrics.py -f /path/to/orbetto_1.perf -f2 /path/to/orbetto_1.perf -hp -diff
# Code coverage for pc bitmap (beta not completely accurate)
python3 metrics.py -bm /path/to/bitmap.roar -elf /path/to/elf_file.elf -cc
```

Once executed, copy the https address into your browser and use the plotly interface to display the desired plot.

Note: Some metrics take a while to calculate (mainly code coverage).

## Advanced metrics and goal

There are already some simple statistical techniques included that can detect outliers, but the bigger picture of this work
is to do regression testing and fuzzing with statistics derived from the instruction trace. For example:
- Regularity of sensor readings [Done].
- Comm link throughputs
- Scheduling latency vs timeouts [Done].
- Thread progress vs semaphores
- Callstack changes (code coverage) [Done].

All these metrics need to be combined into a large latent space that can be diffed (a kind of distance measure) between different versions of PX4.
of PX4 to detect bugs in the code before it flies.

## GCOV

There has been a quick investigation to use a more advanced and also tested tool. The most common is gcov, which is a
test coverage programme from GCC.
Two files are required for gcov to display code coverage:
- .gcno, which is an advanced source file you get when compiling with the GCC -ftest-coverage option
- .gcda, which is created when the GCC -fprofile-arcs option is run.

It should be a simple .gcno file as the flag is already a compile option in PX4.
Theoretically it should be possible to reverse engineer the .gcda file just from the PC values,
(documentation can be found here: https://github.com/gcc-mirror/gcc/blob/master/gcc/gcov-io.h)
However, it is unclear how long this will take and how robust it will be.